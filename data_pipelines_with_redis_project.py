# -*- coding: utf-8 -*-
"""Data Pipelines with Redis Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OoPb-u8lN04ylQY5ALELRYqWxDWIzdtf
"""

import pandas as pd
import redis
import psycopg2
import logging

# Set up logging
logging.basicConfig(filename='data_processing.log', level=logging.ERROR,
                    format='%(asctime)s %(levelname)s %(message)s')

# Redis Cloud Instance Information
redis_host = 'redis-12509.c262.us-east-1-3.ec2.cloud.redislabs.com'
redis_port = 12509
redis_password = 'G19yojPiibstr0P4Z88P8hs0bGmDWqJz'

# Set up Postgres connection details
pg_host = '34.170.193.146'
pg_database = 'telecom'
pg_user = 'admin'
pg_password = 'password'


# Redis Client Object
redis_client = redis.Redis(host=redis_host, port=redis_port, password=redis_password)

def extract_data():
    try:
        # Check if data is cached in Redis
        data_bytes = redis_client.get('customer_call_logs')
        if data_bytes is not None:
            data_str = data_bytes.decode('utf-8')
            data = pd.read_json(data_str)
        else:
            # Read data from CSV file using pandas
            data = pd.read_csv('customer_call_logs.csv')

            # Cache data in Redis for faster retrieval
            redis_client.set('customer_call_logs', data.to_json())
    except Exception as e:
        logging.error(f'Error occurred while caching/reading data from Redis: {e}')
        data = None

    return data


def transform_data(data):
    if data is None:
        return None

    try:
        # Transform data (clean, structure, format)
      data['call_date'] = pd.to_datetime(data['call_date'])
      data['call_duration'] = pd.to_timedelta(data['call_duration'])
      data['call_duration_min'] = data['call_duration'].dt.total_seconds() / 60
      data.drop('call_duration', axis=1, inplace=True)
      # Strip the "$" in the call_cost column
      data['call_cost'] = data['call_cost'].str.strip('$').astype(float)

      # Create new columns for call start time and day of week
      data['call_start_time'] = data['call_date'].dt.time
      data['call_day_of_week'] = data['call_date'].dt.day_name()



    except Exception as e:
        logging.error(f'Error occurred while transforming data: {e}')
        data = None

    return data


def load_data(transformed_data):
    if transformed_data is None:
        return

    try:
        # Connect to Postgres database
        conn = psycopg2.connect(host=pg_host, database=pg_database, user=pg_user, password=pg_password)

        # Create a cursor object
        cur = conn.cursor()

        # Create a table to store the data
        cur.execute('CREATE TABLE IF NOT EXISTS customer_call_logs (\
                     customer_id INT,\
                     call_cost_usd FLOAT,\
                     call_destination VARCHAR,\
                     call_date TIMESTAMP,\
                     call_duration_min FLOAT\
                     )')

        # Insert the transformed data into the database
        for i, row in transformed_data.iterrows():
            cur.execute(f"INSERT INTO customer_call_logs (customer_id, call_cost_usd, call_destination, call_date, call_duration_min) VALUES ({row['customer_id']}, {row['call_cost']}, '{row['call_destination']}', '{row['call_date']}', {row['call_duration_min']})")

        # Commit the changes
        conn.commit()

        # Close the cursor and connection
        cur.close()
        conn.close()
    except Exception as e:
        logging.error(f'Error occurred while loading data to Postgres: {e}')






def data_pipeline():
    # Data pipeline function
    data = extract_data()
    transformed_data = transform_data(data)
    load_data(transformed_data)

if __name__ == '__main__':
    # Run the data pipeline function
    data_pipeline()